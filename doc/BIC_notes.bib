@misc{DaumeIII2009,
author = {{Daume III}, Hal},
file = {:home/afoglia/Documents/papers/programming/17-gmm.pdf:pdf},
keywords = {machine learning},
title = {{Gaussian Mixture Models}},
url = {http://www.cs.utah.edu/~hal/courses/2009F\_ML/out/17-gmm.pdf},
year = {2009}
}
@article{Moore1991,
author = {Moore, Andrew W},
file = {:home/afoglia/Documents/papers/programming/kd-trees-tutorial-moore.pdf:pdf},
number = {209},
title = {{An intoductory tutorial on kd-trees}},
year = {1991}
}
@inproceedings{Pelleg1999,
abstract = {We present new algorithms for the k-means clustering problem. They use the kd-tree data structure to reduce the large number of nearest-neighbor queries issued by the traditional algorithm. Sufficient statistics are stored in the nodes of the kd-tree. Then, an analysis of the geometry of the current cluster centers results in great reduction of the work needed to update the centers. Our algorithms behave exactly as the traditional k-means algorithm. Proofs of correctness are included. The kd-tree can also be used to initialize the k-means starting centers efficiently. Our algorithms can be easily extended to provide fast ways of computing the error of a given cluster assignment, regardless of the method in which those clusters were obtained. We also show how to use them in a setting which allows approximate clustering results, with the benefit of running faster. We have implemented and tested our algorithms on both real and simulated data. Results show a speedup factor of up to 170 on real astrophysical data, and superiority over the naive algorithm on simulated data in up to 5 dimensions. Our algorithms scale well with respect to the number of points and number of centers, allowing for clustering with tens of thousands of centers.},
author = {Pelleg, D and Moore, Andrew},
booktitle = {Proceedings of the Fifth International Conference on Knowledge Discovery in Databases},
file = {:home/afoglia/Documents/papers/programming/pelleg-accelerating.pdf:pdf},
pages = {277----281},
title = {{Accelerating Exact k-means Algorithms with Geometric Reasoning}},
url = {https://www.autonlab.org/autonweb/14663.html?branch=1\&language=2},
year = {1999}
}
@article{Pelleg2000,
author = {Pelleg, Dan and Moore, Andrew},
file = {:home/afoglia/Documents/papers/programming/xmeans.pdf:pdf},
journal = {Proceedings of the Seventeenth International},
title = {{X-means: Extending K-means with efficient estimation of the number of clusters}},
url = {http://staff.utia.cas.cz/nagy/skola/Projekty/Classification/Xmeans.pdf},
year = {2000}
}
@article{Kass1995,
author = {Kass, Robert E and Wasserman, Larry},
file = {:home/afoglia/Documents/papers/programming/Bayesian\_Test\_for\_Nested\_Hypothesis(BIC)\_kass\_and\_wasserman\_1995.pdf:pdf},
journal = {Journal of the American Statistical Association},
keywords = {Bayes information criterion,Laplace's method,Model selection,Null-orthogonal parameters,Orthogonal parameters},
number = {431},
title = {{A Reference Bayesian Test for Nested and Its Relationship to the Schwarz Criterion}},
volume = {90},
year = {1995}
}
